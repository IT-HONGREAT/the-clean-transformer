test:
  hidden_size:  64
  heads: 8
  depth: 3
  max_epochs: 100
  batch_size: 64
  val_ratio: 0.15
  test_ratio: 0.15
  max_length: 30
  lr: 0.0001
  bos_token: "[BOS]"
  eos_token: "[EOS]"
  tokenizer: "beomi/kcbert-base"
  # just so that we can overfit the model to the training data
  dropout: 0.0001
  seed: 410
  # shuffle the training set
  shuffle: true
  data_ver: v0
overfit:
  hidden_size: 64
  heads: 8
  depth: 3
  max_epochs: 100
  batch_size: 128
  val_ratio: 0.15
  test_ratio: 0.15
  max_length: 30
  lr: 0.0001
  bos_token: "[BOS]"
  eos_token: "[EOS]"
  tokenizer: "beomi/kcbert-base"
  # just so that we can overfit the model to the training data
  dropout: 0.0
  seed: 410
  # shuffle the training set
  shuffle: true
  data_ver: v0

